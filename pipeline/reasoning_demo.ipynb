{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c37b11",
   "metadata": {},
   "source": [
    "# Reasoning Direction\n",
    "\n",
    "This notebook aims to estimate the \"reasoning\" direction within the LLM activation space.\n",
    "We're basing this approach on the methodology used to find the \"refusal\" direction, but with a key difference:\n",
    "\n",
    "- **Refusal paper approach**: Used 1 LLM with 2 types of prompts (harmful vs harmless)\n",
    "- **Our approach**: Use 2 models (original vs reasoning-tuned) with the same prompts (GSM8K math problems)\n",
    "\n",
    "We'll collect activations from both models, calculate the difference (reasoning direction),\n",
    "and then test if adding this direction to the non-reasoning model enhances its reasoning capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a99e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "%%capture\n",
    "!pip install transformers transformers_stream_generator tiktoken transformer_lens einops jaxtyping colorama scikit-learn datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2619f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import functools\n",
    "import einops\n",
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "import textwrap\n",
    "import gc\n",
    "import transformers\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from torch import Tensor\n",
    "from typing import List, Callable, Dict, Tuple, Optional, Union\n",
    "from transformer_lens import HookedTransformer, utils\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from jaxtyping import Float, Int\n",
    "from colorama import Fore\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# We turn off automatic differentiation to save GPU memory\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc94de4a",
   "metadata": {},
   "source": [
    "## Load models\n",
    "\n",
    "We'll load both the original model and the reasoning-tuned model using HookedTransformer.\n",
    "If using a HuggingFace model, we can download it directly. If using a local model, make sure it's \n",
    "in the correct directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b7742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model paths - adjust these based on your models\n",
    "MODEL_PATH_ORIGINAL = \"meta-llama/Llama-3.1-8B\"  # Non-reasoning model\n",
    "MODEL_PATH_REASONING = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"  # Reasoning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8884113f",
   "metadata": {},
   "source": [
    "### Optional: Download the models if needed\n",
    "This step can be skipped if you already have the models locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8eacc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to download the reasoning model\n",
    "# model_path = snapshot_download(\n",
    "#     repo_id=MODEL_PATH_REASONING,\n",
    "#     local_dir=MODEL_PATH_REASONING,\n",
    "#     local_dir_use_symlinks=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47189609",
   "metadata": {},
   "source": [
    "### Load both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e1519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original (non-reasoning) model\n",
    "model_original = HookedTransformer.from_pretrained_no_processing(\n",
    "    MODEL_PATH_ORIGINAL,\n",
    "    local_files_only=True,  # Set to True if using local models\n",
    "    dtype=torch.bfloat16,\n",
    "    default_padding_side='left'\n",
    ")\n",
    "model_original.tokenizer.padding_side = 'left'\n",
    "model_original.tokenizer.pad_token = model_original.tokenizer.eos_token\n",
    "\n",
    "print(f\"Loaded non-reasoning model {MODEL_PATH_ORIGINAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f544f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the reasoning model\n",
    "model_reasoning = HookedTransformer.from_pretrained_no_processing(\n",
    "    MODEL_PATH_REASONING,\n",
    "    local_files_only=True,  # Set to True if using local models\n",
    "    dtype=torch.bfloat16,\n",
    "    default_padding_side='left'\n",
    ")\n",
    "model_reasoning.tokenizer.padding_side = 'left'\n",
    "model_reasoning.tokenizer.pad_token = model_reasoning.tokenizer.eos_token\n",
    "\n",
    "print(f\"Loaded reasoning model {MODEL_PATH_REASONING}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6927e6cd",
   "metadata": {},
   "source": [
    "## Set up chat templates and data processing functions\n",
    "\n",
    "We need to define chat templates for both models and create functions to process our data.\n",
    "Different models may have different chat templates, so we adjust accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59abaad",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define chat templates for both models\n",
    "# Adjust these templates based on your specific models\n",
    "ORIGINAL_CHAT_TEMPLATE = \"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "{instruction}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"  # Llama-3 template\n",
    "\n",
    "REASONING_CHAT_TEMPLATE = \"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "{instruction}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"  # DeepSeek template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f43b675",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define utility functions for processing data and collecting activations\n",
    "\n",
    "def tokenize_instructions(\n",
    "    tokenizer: AutoTokenizer,\n",
    "    instructions: List[str],\n",
    "    chat_template: str\n",
    ") -> Int[Tensor, 'batch_size seq_len']:\n",
    "    \"\"\"Tokenize instructions using the specified chat template.\"\"\"\n",
    "    prompts = [chat_template.format(instruction=instruction) for instruction in instructions]\n",
    "    return tokenizer(prompts, padding=True, truncation=False, return_tensors=\"pt\").input_ids\n",
    "\n",
    "def collect_activations(\n",
    "    model: HookedTransformer,\n",
    "    tokenized_inputs: Int[Tensor, 'batch_size seq_len'],\n",
    "    batch_size: int = 8\n",
    ") -> Dict[str, Tensor]:\n",
    "    \"\"\"Collect activations from a model for the given inputs.\"\"\"\n",
    "    activations = {}\n",
    "    \n",
    "    for i in tqdm(range(0, len(tokenized_inputs), batch_size)):\n",
    "        batch = tokenized_inputs[i:i+batch_size]\n",
    "        \n",
    "        # Run the model and cache activations\n",
    "        logits, cache = model.run_with_cache(\n",
    "            batch, \n",
    "            names_filter=lambda hook_name: 'resid' in hook_name, \n",
    "            device='cpu'  # Use CPU to avoid OOM errors; switch to 'cuda' if you have enough VRAM\n",
    "        )\n",
    "        \n",
    "        # First batch, initialize the dictionary\n",
    "        if not activations:\n",
    "            activations = {key: [cache[key]] for key in cache}\n",
    "        else:\n",
    "            # Append to existing cache\n",
    "            for key in cache:\n",
    "                activations[key].append(cache[key])\n",
    "                \n",
    "        # Clear memory\n",
    "        del logits, cache\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    activations = {k: torch.cat(v) for k, v in activations.items()}\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c452769",
   "metadata": {},
   "source": [
    "## Load and prepare GSM8K dataset\n",
    "\n",
    "We'll use the GSM8K dataset which contains math problems that require reasoning to solve.\n",
    "We'll append \"please provide your answer first, then your reasoning\" to each problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd98266",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Load GSM8K dataset\n",
    "gsm8k = load_dataset(\"gsm8k\", \"main\")\n",
    "print(f\"Loaded GSM8K dataset with {len(gsm8k['train'])} training examples and {len(gsm8k['test'])} test examples\")\n",
    "\n",
    "# Look at a sample problem\n",
    "print(\"\\nSample problem:\")\n",
    "print(gsm8k[\"train\"][0][\"question\"])\n",
    "print(\"\\nSample answer:\")\n",
    "print(gsm8k[\"train\"][0][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11cc56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to prepare prompts\n",
    "def prepare_prompts(problems: List[str]) -> List[str]:\n",
    "    \"\"\"Add the reasoning instruction to each problem.\"\"\"\n",
    "    return [f\"{problem}\\n\\nPlease provide your answer first, then your reasoning.\" for problem in problems]\n",
    "\n",
    "# Prepare prompts for training and testing\n",
    "train_problems = [item[\"question\"] for item in gsm8k[\"train\"]]\n",
    "test_problems = [item[\"question\"] for item in gsm8k[\"test\"]]\n",
    "\n",
    "# Limit the number of problems to reduce computation time\n",
    "N_PROBLEMS = 100  # Adjust based on available compute\n",
    "train_problems = train_problems[:N_PROBLEMS]\n",
    "test_problems = test_problems[:min(20, len(test_problems))]  # Smaller test set\n",
    "\n",
    "train_prompts = prepare_prompts(train_problems)\n",
    "test_prompts = prepare_prompts(test_problems)\n",
    "\n",
    "print(f\"Prepared {len(train_prompts)} training prompts and {len(test_prompts)} test prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418b16ce",
   "metadata": {},
   "source": [
    "## Collect activations from both models\n",
    "\n",
    "Now we'll run the same prompts through both models and collect their activations.\n",
    "This is the key step where we gather the data needed to compute the reasoning direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea3899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the math problems for both models\n",
    "tokenized_prompts_original = tokenize_instructions(\n",
    "    model_original.tokenizer, \n",
    "    train_prompts, \n",
    "    ORIGINAL_CHAT_TEMPLATE\n",
    ")\n",
    "\n",
    "tokenized_prompts_reasoning = tokenize_instructions(\n",
    "    model_reasoning.tokenizer, \n",
    "    train_prompts, \n",
    "    REASONING_CHAT_TEMPLATE\n",
    ")\n",
    "\n",
    "print(f\"Tokenized prompts shape (original): {tokenized_prompts_original.shape}\")\n",
    "print(f\"Tokenized prompts shape (reasoning): {tokenized_prompts_reasoning.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78d15ac",
   "metadata": {},
   "source": [
    "### Collect activations (this may take a while)\n",
    "We'll run both models on the same inputs and collect their activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3534dd71",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"Collecting activations from the original model...\")\n",
    "original_activations = collect_activations(model_original, tokenized_prompts_original)\n",
    "print(\"Done collecting activations from the original model\")\n",
    "\n",
    "print(\"Collecting activations from the reasoning model...\")\n",
    "reasoning_activations = collect_activations(model_reasoning, tokenized_prompts_reasoning)\n",
    "print(\"Done collecting activations from the reasoning model\")\n",
    "\n",
    "# Optional: Save activations to disk to avoid recomputing\n",
    "torch.save(original_activations, 'original_activations.pth')\n",
    "torch.save(reasoning_activations, 'reasoning_activations.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9423de4f",
   "metadata": {},
   "source": [
    "## Calculate the reasoning direction\n",
    "\n",
    "Now we'll calculate the reasoning direction by taking the difference between\n",
    "activations from the reasoning model and the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f7cf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_act_idx(cache_dict, act_name, layer):\n",
    "    \"\"\"Helper function to get activations from a specific layer.\"\"\"\n",
    "    key = (act_name, layer,)\n",
    "    return cache_dict[utils.get_act_name(*key)]\n",
    "\n",
    "# The activation layers to analyze\n",
    "activation_layers = ['resid_pre', 'resid_mid', 'resid_post']\n",
    "\n",
    "# Calculate reasoning directions\n",
    "reasoning_directions = {k: [] for k in activation_layers}\n",
    "\n",
    "for layer_num in tqdm(range(1, model_original.cfg.n_layers)):\n",
    "    pos = -1  # Focus on the last token position\n",
    "    \n",
    "    for layer in activation_layers:\n",
    "        # Get mean activations for each model\n",
    "        original_mean_act = get_act_idx(original_activations, layer, layer_num)[:, pos, :].mean(dim=0)\n",
    "        reasoning_mean_act = get_act_idx(reasoning_activations, layer, layer_num)[:, pos, :].mean(dim=0)\n",
    "        \n",
    "        # Calculate the difference and normalize to get the direction\n",
    "        reasoning_dir = reasoning_mean_act - original_mean_act\n",
    "        reasoning_dir = reasoning_dir / reasoning_dir.norm()\n",
    "        \n",
    "        reasoning_directions[layer].append(reasoning_dir)\n",
    "\n",
    "# Save the reasoning directions\n",
    "torch.save(reasoning_directions, 'reasoning_dirs.pth')\n",
    "print(\"Reasoning directions calculated and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34968529",
   "metadata": {},
   "source": [
    "## Score and rank reasoning directions\n",
    "\n",
    "Now we'll sort the reasoning directions by their magnitude to identify\n",
    "which layers might have the strongest reasoning signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad5304d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Get all calculated potential reasoning dirs, sort them in descending order\n",
    "# based on their mean() magnitude\n",
    "activation_layers = ['resid_pre']  # We can start with just this layer as it's often sufficient\n",
    "\n",
    "# Flatten and score all directions\n",
    "activation_scored = sorted(\n",
    "    [reasoning_directions[layer][l-1] for l in range(1, model_original.cfg.n_layers) for layer in activation_layers], \n",
    "    key=lambda x: abs(x.mean()), \n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "print(f\"Ranked {len(activation_scored)} potential reasoning directions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decfa70d",
   "metadata": {},
   "source": [
    "## Test the reasoning direction\n",
    "\n",
    "Now we'll define a hook to add the reasoning direction to the model's activations\n",
    "during inference and test if it enhances the model's reasoning capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e0270f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def reasoning_enhancement_hook(\n",
    "    activation: Float[Tensor, \"... d_act\"],\n",
    "    hook: HookPoint,\n",
    "    direction: Float[Tensor, \"d_act\"],\n",
    "    strength: float = 1.0\n",
    "):\n",
    "    \"\"\"Hook to add the reasoning direction to activations.\"\"\"\n",
    "    if activation.device != direction.device:\n",
    "        direction = direction.to(activation.device)\n",
    "    \n",
    "    # Project the activation onto the reasoning direction and add it back\n",
    "    # Unlike refusal where we subtract, here we're adding more of the reasoning direction\n",
    "    proj = einops.einsum(activation, direction.view(-1, 1), '... d_act, d_act single -> ... single') * direction\n",
    "    return activation + (strength * direction)\n",
    "\n",
    "def generate_with_hooks(\n",
    "    model: HookedTransformer,\n",
    "    toks: Int[Tensor, 'batch_size seq_len'],\n",
    "    max_tokens_generated: int = 100,\n",
    "    fwd_hooks = [],\n",
    ") -> List[str]:\n",
    "    \"\"\"Generate text with specified hooks applied.\"\"\"\n",
    "    all_toks = torch.zeros(\n",
    "        (toks.shape[0], toks.shape[1] + max_tokens_generated), \n",
    "        dtype=torch.long, \n",
    "        device=toks.device\n",
    "    )\n",
    "    all_toks[:, :toks.shape[1]] = toks\n",
    "    \n",
    "    for i in range(max_tokens_generated):\n",
    "        with model.hooks(fwd_hooks=fwd_hooks):\n",
    "            logits = model(all_toks[:, :-max_tokens_generated + i])\n",
    "            next_tokens = logits[:, -1, :].argmax(dim=-1)  # greedy sampling\n",
    "            all_toks[:, -max_tokens_generated + i] = next_tokens\n",
    "    \n",
    "    return model.tokenizer.batch_decode(all_toks[:, toks.shape[1]:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bd0462",
   "metadata": {},
   "source": [
    "## Evaluate the reasoning enhancement\n",
    "\n",
    "Now we'll test our reasoning direction on a few example problems and compare\n",
    "the baseline model outputs with the reasoning-enhanced outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8ba985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top reasoning direction to test\n",
    "top_reasoning_dir = activation_scored[0]\n",
    "print(\"Selected top reasoning direction for testing\")\n",
    "\n",
    "# Create hooks to inject reasoning direction\n",
    "strength = 1.0  # Adjust this value to control the magnitude of the effect\n",
    "hook_fn = functools.partial(reasoning_enhancement_hook, direction=top_reasoning_dir, strength=strength)\n",
    "\n",
    "# Create hooks for all layers (or you can target specific layers)\n",
    "fwd_hooks = [\n",
    "    (utils.get_act_name(act_name, l), hook_fn) \n",
    "    for l in range(model_original.cfg.n_layers) \n",
    "    for act_name in ['resid_pre', 'resid_mid', 'resid_post']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e0fe9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Test on a few examples\n",
    "N_TEST_EXAMPLES = 3\n",
    "print(f\"Testing on {N_TEST_EXAMPLES} examples from the test set\")\n",
    "\n",
    "for i in range(N_TEST_EXAMPLES):\n",
    "    test_prompt = test_prompts[i]\n",
    "    print(f\"\\n\\n--- EXAMPLE {i+1} ---\")\n",
    "    print(f\"PROBLEM:\\n{test_prompt}\")\n",
    "    \n",
    "    # Tokenize the test prompt\n",
    "    test_tokens = tokenize_instructions(\n",
    "        model_original.tokenizer, \n",
    "        [test_prompt], \n",
    "        ORIGINAL_CHAT_TEMPLATE\n",
    "    )\n",
    "    \n",
    "    # Generate baseline response (without reasoning enhancement)\n",
    "    baseline_response = generate_with_hooks(model_original, test_tokens)\n",
    "    print(\"\\nBASELINE RESPONSE:\")\n",
    "    print(baseline_response[0])\n",
    "    \n",
    "    # Generate reasoning-enhanced response\n",
    "    enhanced_response = generate_with_hooks(model_original, test_tokens, fwd_hooks=fwd_hooks)\n",
    "    print(\"\\nREASONING-ENHANCED RESPONSE:\")\n",
    "    print(enhanced_response[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a7192",
   "metadata": {},
   "source": [
    "## Systematic Evaluation\n",
    "\n",
    "To properly evaluate the effectiveness of our reasoning direction,\n",
    "we'll test it on more examples and compare the quality of the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16772229",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate_reasoning(\n",
    "    model: HookedTransformer,\n",
    "    problems: List[str],\n",
    "    chat_template: str,\n",
    "    reasoning_hooks=None,\n",
    "    max_tokens: int = 150,\n",
    "    batch_size: int = 4\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Evaluate model performance with and without reasoning enhancement.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(problems), batch_size)):\n",
    "        batch_problems = problems[i:i+batch_size]\n",
    "        tokens = tokenize_instructions(model.tokenizer, batch_problems, chat_template)\n",
    "        \n",
    "        # Generate without reasoning enhancement\n",
    "        baseline_responses = generate_with_hooks(model, tokens, max_tokens_generated=max_tokens)\n",
    "        \n",
    "        # Generate with reasoning enhancement if hooks provided\n",
    "        if reasoning_hooks:\n",
    "            enhanced_responses = generate_with_hooks(\n",
    "                model, tokens, max_tokens_generated=max_tokens, fwd_hooks=reasoning_hooks\n",
    "            )\n",
    "        else:\n",
    "            enhanced_responses = [\"No enhancement applied\"] * len(batch_problems)\n",
    "        \n",
    "        # Store results\n",
    "        for j, (problem, baseline, enhanced) in enumerate(\n",
    "            zip(batch_problems, baseline_responses, enhanced_responses)\n",
    "        ):\n",
    "            results.append({\n",
    "                \"problem\": problem,\n",
    "                \"baseline\": baseline,\n",
    "                \"enhanced\": enhanced\n",
    "            })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78112b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on a larger test set\n",
    "evaluation_results = evaluate_reasoning(\n",
    "    model_original,\n",
    "    test_prompts[:10],  # Use more examples for a better evaluation\n",
    "    ORIGINAL_CHAT_TEMPLATE,\n",
    "    reasoning_hooks=fwd_hooks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fec300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print and analyze evaluation results\n",
    "for i, result in enumerate(evaluation_results):\n",
    "    print(f\"\\n--- EVALUATION EXAMPLE {i+1} ---\")\n",
    "    print(f\"PROBLEM:\\n{result['problem']}\")\n",
    "    print(f\"\\nBASELINE SOLUTION:\\n{result['baseline']}\")\n",
    "    print(f\"\\nREASONING-ENHANCED SOLUTION:\\n{result['enhanced']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d760094",
   "metadata": {},
   "source": [
    "## Future Directions\n",
    "\n",
    "Some potential improvements and extensions to this work:\n",
    "\n",
    "1. **Fine-tune the strength parameter**: Experiment with different values of the strength parameter\n",
    "2. **Layer-specific intervention**: Apply the reasoning direction to specific layers only\n",
    "3. **Quantitative evaluation**: Develop metrics to measure reasoning quality\n",
    "4. **Orthogonalization**: Create a model with permanent reasoning enhancement by orthogonalizing the weights\n",
    "5. **Multiple reasoning directions**: Identify different aspects of reasoning (deduction, induction, etc.)\n",
    "\n",
    "This approach of comparing model activations to find meaningful directions in the activation space\n",
    "could be extended to many other capabilities beyond reasoning."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
